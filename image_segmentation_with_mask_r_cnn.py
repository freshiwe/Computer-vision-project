# -*- coding: utf-8 -*-
"""Image Segmentation with Mask R-CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gXmKJIlpVsO8jeyotsLp9idsZMeTPmV_

# Computer Vision Masterclass - Image Segmentation with Mask R-CNN

> Note: After an Colab update in December 2022, Tensorflow version 1.x is no longer accessible. So let's use the updated version from the official repository, which has support for the latest versions of Tensorflow.  

> A few more small changes will be necessary (they are demonstrated throughout this Colab)
* Clone from other repository (https://github.com/alsombra/Mask_RCNN-TF2)
* Change from Mask_RCNN (folder name) to Mask_RCNN-TF2
* Add compatibility code (the 5 lines under the title "[ ! ] Compatibility Update")
* Remove the commands that downgrade h5py and tensorflow (they are already removed from this Colab)

## Downloading the repository
"""

!git clone https://github.com/alsombra/Mask_RCNN-TF2  # updated repository

# Commented out IPython magic to ensure Python compatibility.
# %cd Mask_RCNN-TF2

pwd

!pip install -r requirements.txt

!python setup.py install

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

pwd

"""## Importing the libraries"""

!pip install numpy==1.23.1

import os
import sys
import cv2
import numpy as np
import skimage.io
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

np.__version__

import tensorflow as tf

tf.__version__

ROOT_DIR = os.path.abspath('./Mask_RCNN-TF2')
ROOT_DIR

sys.path

sys.path.append(ROOT_DIR)

sys.path

from mrcnn import utils
from mrcnn import visualize
import mrcnn.model as modellib

# https://cocodataset.org/#home
sys.path.append(os.path.join(ROOT_DIR, 'samples/coco/'))

sys.path

import coco

MODEL_DIR = os.path.join(ROOT_DIR, 'logs')
IMAGE_DIR = os.path.join(ROOT_DIR, 'images')

MODEL_DIR, IMAGE_DIR

"""### [ ! ] Compatibility Update
Run the 5 lines below so we don't have any issues when running with the latest versions of Tensorflow
"""

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

"""## Loading the pre-trained neural network"""

COCO_MODEL_PATH = os.path.join(ROOT_DIR, 'mask_rcnn_coco.h5')

utils.download_trained_weights(COCO_MODEL_PATH)

class InferenceConfig(coco.CocoConfig):
  GPU_COUNT = 1
  IMAGES_PER_GPU = 1

config = InferenceConfig()

config.display()

MODEL_DIR

network = modellib.MaskRCNN(mode='inference', model_dir=MODEL_DIR, config=config)

network.load_weights(COCO_MODEL_PATH, by_name=True)

"""## Detecting objects"""

class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
               'bus', 'train', 'truck', 'boat', 'traffic light',
               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',
               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',
               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
               'kite', 'baseball bat', 'baseball glove', 'skateboard',
               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',
               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',
               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',
               'teddy bear', 'hair drier', 'toothbrush']

len(class_names)

class_names[1], class_names.index('person')

image2 = cv2.imread('/content/Mask_RCNN-TF2/images/2516944023_d00345997d_z.jpg')
plt.imshow(image2); # BGR

image = skimage.io.imread('/content/Mask_RCNN-TF2/images/2516944023_d00345997d_z.jpg') # RGB

plt.imshow(image);

class_names[17], class_names[1], class_names[14]

results = network.detect([image], verbose=0)
results

r = results[0]

visualize.display_instances(image, r['rois'], r['masks'],
                            r['class_ids'], class_names, r['scores'])

"""## Removing the background"""

np.unique(r['masks'], return_counts=True)

r['masks']

def segment(image, r, index):
  mask = r['masks'][:,:,index]
  #print(mask)
  #print(mask.shape)

  mask = np.stack((mask,) * 3, axis = -1)
  #print(mask)
  #print(mask.shape)

  mask = mask.astype('uint8')
  #print(mask)
  bg = 255 - mask * 255
  #print(mask, mask.min(), mask.max())

  mask_show = np.invert(bg)
  #print(mask_show)
  mask_img = image * mask
  #print(mask_img)

  result = mask_img + bg
  return result, mask_show

image.shape, 425 * 640

segmentation, mask_obj = segment(image, r, 0)

segmentation

mask_obj

def show_segment(image, r, index, show_mask = False):
  segmentation, mask_obj = segment(image, r, index)
  plt.subplots(1, figsize=(16,16))
  plt.axis('off')
  if show_mask == True:
    plt.imshow(np.concatenate([mask_obj, segmentation], axis = 1))
  else:
    plt.imshow(np.concatenate([image, segmentation], axis = 1))

show_segment(image, r, 0, False)

show_segment(image, r, 0, True)

r['rois'], len(r['rois'])

for index in range(len(r['rois'])):
  show_segment(image, r, index, True)

"""## Segmentation in videos"""

from google.colab import drive
drive.mount('/content/drive')

capture = cv2.VideoCapture('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Videos/video_street2.mp4')
connected, frame = capture.read()
connected

frame.shape

save_video = cv2.VideoWriter('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Videos/video_street2_result_seg.avi',
                             cv2.VideoWriter_fourcc(*'XVID'), 24, (frame.shape[1], frame.shape[0]))

!cp /content/drive/MyDrive/Cursos\ -\ recursos/Computer\ Vision\ Masterclass/PyCharm/video_functions.py ./Mask_RCNN-TF2/mrcnn

from mrcnn import video_functions

colors = video_functions.random_colors(len(class_names), 55)
len(colors)

print(colors)

def show(img):
  fig = plt.gcf()
  fig.set_size_inches(16,10)
  plt.axis('off')
  plt.imshow(img)
  plt.show()

frame_show = 20
current_frame = 0

while (cv2.waitKey(1) < 0):
  connected, frame = capture.read()

  if not connected:
    break

  results = network.detect([frame], verbose=0)
  r = results[0]

  processed_frame = video_functions.display_instances(frame, r['rois'], r['masks'],
                                                      r['class_ids'], class_names, r['scores'], colors=colors)

  if current_frame <= frame_show:
    show(processed_frame)
    current_frame += 1

  save_video.write(cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB))
save_video.release()

"""## Homework"""

images = [os.path.join('/content/Mask_RCNN-TF2/images', f) for f in os.listdir('/content/Mask_RCNN-TF2/images')]
images

for image in images:
  #try:
  current_image = skimage.io.imread(image)
  (H, W) = current_image.shape[:2]
  #except:
  #  continue

  results = network.detect([current_image], verbose=0)
  r = results[0]
  visualize.display_instances(current_image, r['rois'], r['masks'],
                              r['class_ids'], class_names, r['scores'])